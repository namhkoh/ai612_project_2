{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Project 2\n",
    "\n",
    "## Outline\n",
    "1. Prerequisites\n",
    "2. Clone the GitHub Repository and Install Dependencies\n",
    "3. User Agent\n",
    "4. Tool-calling DB Agent using GPT-4o-mini\n",
    "5. Running Inference\n",
    "6. Viewing the Conversation Trajectories\n",
    "7. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()\n",
    "# Please enter your API key\n",
    "new_api_key = ''\n",
    "while len(new_api_key) == 0:\n",
    "    new_api_key = getpass.getpass(\"Please input your API key: \")\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the GitHub Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /content\n",
    "# !rm -rf ai612_project_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cloning the GitHub repository\n",
    "# !git clone -q https://github.com/benchay1999/ai612_project_2.git\n",
    "# %cd ai612_project_2\n",
    "\n",
    "# # Installing dependencies\n",
    "# ! pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('.env'):\n",
    "    os.remove('.env')\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(f'OPENAI_API_KEY=\"{new_api_key}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User LLM\n",
    "This User LLM simulates the behavior of users who interact with text-to-SQL systems without SQL knowledge. Let's take a look at the system prompt of the User LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system prompt:\n",
      "You are a human user who wants to retrieve data from an EHR database by interacting with an DB agent.\n",
      "The important thing is that, you have no background knowledge about the Structured Query Language. You should not act like a person who knows SQL.\n",
      "In other words, you are a person that asks a DB agent with a natural language, and you only understand the execution result of the SQL query the DB agent executes.\n",
      "User instruction: \n",
      "\n",
      "Instruction: Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.\n",
      "\n",
      "\n",
      "[VERY IMPORTANT RULES]\n",
      "1. The current time is 2100-12-31 23:59:00.\n",
      "2. You don't know SQL and have only a general understanding of the database contents.\n",
      "3. Explain your question in plain language so that the DB agent understands what you want.\n",
      "4. Keep your messages short and to the point, avoiding words like \"please\" or \"thank you.\"\n",
      "5. Start with a short, vague question to convey your goal in the first turn.\n",
      "6. Don't reveal all your needs at once. Share one or two sentences per turn.\n",
      "7. Don't repeat the user instruction. Use your own words to describe what you need.\n",
      "8. You don't know the form in which the requested data is stored. If the DB agent cannot retrieve the data you want, ask it to explore the database for their correct format.\n",
      "9. Only provide information relevant to asking or replying to the DB agent.\n",
      "10. Don't make up or assume extra information or assumptions not given in the user instruction.\n",
      "11. Even if the DB agent hands the task back to you (e.g., retrieving the database schema, generating or executing SQL queries, reviewing SQL queries, or using API calls), do not attempt to complete the task yourself. You lack access to external resources, so instruct the DB agent to handle the entire task. Respond only to the agent's clarifications based on the user instruction.\n",
      "12. You are the user adhering to the user instructions, seeking help from the database agent because you don't have the expertise in SQL or database. You are not assisting the agent, but the agent is assisting you to complete the task.\n",
      "13. If the DB agent gives a partial answer, don't complete it yourself. Ask the agent to complete it (e.g., phrasing answers aligned with the user instruction or simple calculation, etc).\n",
      "14. At the end, ask the DB agent to check if your question is fully satisfied as every detail conditions stated in the user instruction. If not, ask for the remaining parts.\n",
      "15. If the answer satisfies your goal completely, generate `###END###` to end the conversation.\n",
      "16. Do not ask questions beyond the user instructions. Even if the DB agent says feel free to ask, stick to the instructions provided (e.g., do not request additional timestamps or any other information not specified).\n",
      "17. End the conversation immediately after the user instruction is fully satisfied.\n",
      "18. Keep the conversation natural, not robotic.\n",
      "19. If not specified in the user instruction, you should consider all the values the DB agent retrieves.\n",
      "20. Do not respond with a fake execution result of the SQL query, or made up information about the database schema.\n",
      "21. NEVER provide information you don't have access to e.g., information related to the database schema, database contents, execution result of the SQL query, etc.\n",
      "22. If the DB agent replies only with the SQL query, you should say \"I have no knowledge about the Structured Query Language. Give me the explanation or the result of the SQL query.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.envs.user import LLMUser\n",
    "# dummy user agent\n",
    "user_agent = LLMUser(model=\"gpt-4o-mini\")\n",
    "# system prompt for the user agent\n",
    "print(f\"system prompt:\\n{user_agent.build_system_prompt('Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"user prompt\" for the User LLM is \"Hi! How can I help you today?\"\n",
    "This way, the User LLM generates a natural language question to address the \"User instruction\" in the above system prompt. \n",
    "\n",
    "Note that you can't modify the system prompt and the user prompt of the User LLM. Also, the User LLM should only be ran by GPT-4o-mini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The sample validation dataset is in the `src/envs/mimic_iv/valid_data.json`. It contains 10 samples for this task. The `src/envs/mimic_iv/test_data.json` contains the same information as in the validation dataset, but with gold SQL and gold answer field removed.\n",
    "\n",
    "IMPORTANT: When created your own custom validation set, make sure that the name of the JSON file is `src/envs/mimic_iv/valid_data.json`. Plus, when given test data, it should be exactly stored in `src/envs/mimic_iv/test_data.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'task_id': '0', 'instruction': 'Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.', 'gold_sql': 'SELECT gender FROM patients WHERE subject_id = 10027602', 'gold_answer': [['f']]}, {'task_id': '1', 'instruction': 'Your goal is to find all the routes of administration for isosorbide dinitrate for patients in the database.', 'gold_sql': \"SELECT DISTINCT prescriptions.route FROM prescriptions WHERE prescriptions.drug = 'isosorbide dinitrate'\", 'gold_answer': [['po/ng']]}]\n",
      "[{'task_id': '11', 'instruction': 'Your goal is to identify medications prescribed to a patient following a specific surgery. Specifically, you are interested in patient ID 10016810 and want to know the medications with prescription start times recorded within the same hospital admission as their appendectomy. Due to the nature of the database, prescription start times may be recorded before the surgery, so you want to focus on prescriptions within the same hospital admission record as the appendectomy. If there is no record of an appendectomy for this patient, end the conversation.'}, {'task_id': '12', 'instruction': \"Your goal is to find information related to a patient's vital signs. Specifically, you are interested in patient ID 10021487 and you want to know when the patient's temperature was last measured during the current admission.\"}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"src/envs/mimic_iv/valid_data.json\", 'r') as f:\n",
    "    valid_data = json.load(f)\n",
    "with open(\"src/envs/mimic_iv/test_data.json\", 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(valid_data[:2])\n",
    "print(test_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the formatted version of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task(task_id='0', instruction='Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.', gold_sql='SELECT gender FROM patients WHERE subject_id = 10027602', gold_answer=[['f']]), Task(task_id='1', instruction='Your goal is to find all the routes of administration for isosorbide dinitrate for patients in the database.', gold_sql=\"SELECT DISTINCT prescriptions.route FROM prescriptions WHERE prescriptions.drug = 'isosorbide dinitrate'\", gold_answer=[['po/ng']])]\n",
      "[Task(task_id='11', instruction='Your goal is to identify medications prescribed to a patient following a specific surgery. Specifically, you are interested in patient ID 10016810 and want to know the medications with prescription start times recorded within the same hospital admission as their appendectomy. Due to the nature of the database, prescription start times may be recorded before the surgery, so you want to focus on prescriptions within the same hospital admission record as the appendectomy. If there is no record of an appendectomy for this patient, end the conversation.', gold_sql=None, gold_answer=None), Task(task_id='12', instruction=\"Your goal is to find information related to a patient's vital signs. Specifically, you are interested in patient ID 10021487 and you want to know when the patient's temperature was last measured during the current admission.\", gold_sql=None, gold_answer=None)]\n"
     ]
    }
   ],
   "source": [
    "from src.types import Task\n",
    "valid_tasks = [Task(**task) for task in valid_data]\n",
    "print(valid_tasks[:2])\n",
    "test_tasks = [Task(**task) for task in test_data]\n",
    "print(test_tasks[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline DB Agent - Tool-calling\n",
    "Now, we will take a look into the tool-calling agent. It uses the following 4 tools:\n",
    "- `sql_db_list_tables`: Get the list of table names in the database.\n",
    "- `sql_db_schema`: Get the columns of a specific table and its sample rows.\n",
    "- `value_substring_search`: Retrieve up to k values from a specific column that contains the specified substring.\n",
    "- `sql_db_query`: Execute a SQL query against the database and get back the result. If the query is not correct, an error message will be returned. The maximum number of results to return is 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the system prompt of the baseline agent. It contains \"domain policies\" i.e., rules that the DB agent should follow in the MIMIC_IV database. You can see the rules in the \"Rules\" section of the system prompt. We don't recommend changing the domain policies, but you can freely change the system prompt above the \"Rules\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system prompt:\n",
      "- You are a SQL agent that translates natural language questions into precise SQL queries for electronic health records (EHR).\n",
      "- You are currently engaged in a conversation with a user who wants to retrieve data from an EHR database.\n",
      "- If the user's request is ambiguous or missing crucial information (e.g., filtering criteria), you must ask clarifying questions in plain language.\n",
      "- You can interact with the database to learn more about its schema or the values stored in it by using the tools provided.\n",
      "- Do not invent or fabricate any information not provided by the user or the tools.\n",
      "- You should make at most one tool call at a time.\n",
      "- If you do call a tool, do not respond to the user in that same turn.\n",
      "- Do not generate SQL queries directly without knowing the database schema and values intended to be used in the SQL query by calling substring_search_tool.\n",
      "- When the user asks for specific diagnoses, procedures, medications, or lab tests, try your best to use the tool to search for relevant information in the database and determine if it relates to the user's request.\n",
      "- Only when you have gathered all necessary information from the user or the database, produce a single, valid SQL query that fully reflects the user's request.\n",
      "- Avoid partial or speculative queries that could cause confusion or yield inaccurate results.\n",
      "- Your performance is evaluated based on the latest SQL query you generate, so when generating a new SQL query for the user's request, avoid relying on previous results but instead rewrite it from scratch to fully capture the user's intent and ensure it is accurately assessed.\n",
      "\n",
      "Rules:\n",
      "- Task:\n",
      "  - The DB agent is required to use SQL at least once to retrieve answers during the conversation, as all questions pertain to patient records in the database.\n",
      "  - When searching for specific values stored in the database (e.g., diagnosis names or drug names), retrieve all relevant items, then narrow down to what the user specifically wants. The user does not know the exact form of the values stored in the database.\n",
      "  - When presenting answers to the user based on SQL output, use the exact forms from the SQL output verbatim (e.g., recorded timestamps, medication names, or diagnosis names).\n",
      "  - For calculations that may result in decimal points (e.g., number of days or hours), present the result rounded to three decimal places.\n",
      "  - The performance of the DB agent is evaluated based only on the latest SQL query generated. When creating a new SQL query for an updated user's request, rewrite it from scratch to fully capture the user's latest intent in a single SQL query.\n",
      "  - Sometimes, there may be a request that cannot be fulfilled by the DB agent (e.g., the user's request is beyond SQL tasks or no results are found). In that case, the DB agent must state which part of the request you cannot fulfill and ask the user to provide further clarification or try a different request.\n",
      "  - Do not transfer the task to a human; human interaction is only allowed for gathering extra information you need to solve the user's request.\n",
      "- SQL generation:\n",
      "  - Use SQLite for SQL query generation.\n",
      "  - The current time is '2100-12-31 23:59:00'. When referring to time, do not use SQLite's native functions like now. Instead, use '2100-12-31 23:59:00' for 'now', '2100-12-31' for 'today', '2100-12' for 'this month', and '2100' for 'this year'.\n",
      "  - Use DENSE_RANK() when asked for ranking results, but retrieve only the relevant items, excluding their counts or ranks. When the question does not explicitly mention ranking, do not use DENSE_RANK().\n",
      "  - For cost-related questions, use cost.event_type to specify the event type ('procedures_icd', 'labevents', 'prescriptions', 'diagnoses_icd') when retrieving costs for procedures, lab events, prescriptions, or diagnoses, respectively. When retrieving costs for procedures, join cost.event_id with procedures_icd.row_id. For lab events, join with labevents.row_id. For prescriptions, join with prescriptions.row_id. For diagnoses, join with diagnoses_icd.row_id.\n",
      "  - Do not calculate the age on your own, use the age stored in the database. The age remains constant even if the hospital stay exceeds one year.\n",
      "  - Use inputevents for input-related values and outputevents for output-related values.\n",
      "  - The prescriptions table stores ordered or prescribed medications, while the inputevents table records administered drugs\n",
      "  - When asked about the careunit, refer to the careunit information in the transfer table.\n",
      "  - When asked to retrieve procedures, diagnoses, or lab tests, return their names or labels of their medical codes (i.e., procedure: d_icd_procedures.long_title, diagnosis: d_icd_diagnoses.long_title, lab test: d_labitems.label).\n",
      "  - When a question involves the time of diagnosis in relation to other types of events, use the first diagnosis time for each patient (if not specified otherwise).\n",
      "- Grading criteria:\n",
      "  - The DB agent's performance evaluation is solely based on the final SQL query generated in the conversation.\n",
      "  - For accurate assessment, each new SQL query must be written from scratch to comprehensively address the user's latest request, without depending on previous query results.\n",
      "  - The DB agent is limited to 30 total interactions with the user and database combined, requiring efficient use of available interactions.\n",
      "  - For any questions involving calculations or data aggregation, the DB agent must use SQL queries rather than relying on LLM capabilities, as evaluation is based exclusively on SQL query accuracy.\n"
     ]
    }
   ],
   "source": [
    "from src.agents.tool_calling_agent import ToolCallingAgent\n",
    "with open(\"src/envs/mimic_iv/rules.txt\", 'r') as f:\n",
    "    db_agent_rules = f.read()\n",
    "# dummy tool-calling agent\n",
    "tc_agent = ToolCallingAgent(tools_info=[], rule=db_agent_rules, model=\"gpt-4o-mini\")\n",
    "# system prompt for the tool-calling agent\n",
    "print(f\"system prompt:\\n{tc_agent.instruction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the tools the DB Agent uses. It can be found in the `src/envs/mimic_iv/tools/` folder. When implementing your own tools, we recommend to create the necessary files in the same folder as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_db_list_tables:\n",
      "{'type': 'function', 'function': {'name': 'sql_db_list_tables', 'description': 'Get the list of table names in the database.', 'parameters': {'type': 'object', 'properties': {'tool_input': {'type': 'string', 'description': 'An empty string; no input required.'}}, 'required': []}}}\n",
      "sql_db_schema:\n",
      "{'type': 'function', 'function': {'name': 'sql_db_schema', 'description': 'Get the columns of a specific table and its sample rows.', 'parameters': {'type': 'object', 'properties': {'table_names': {'type': 'string', 'description': 'A comma-separated list of table names to retrieve schema and sample rows for.'}}, 'required': ['table_names']}}}\n",
      "value_substring_search:\n",
      "{'type': 'function', 'function': {'name': 'substring_search_tool', 'description': 'Retrieve up to k values from a column that contains the specified substring.', 'parameters': {'type': 'object', 'properties': {'table': {'type': 'string', 'description': 'The table name.'}, 'column': {'type': 'string', 'description': 'The column name.'}, 'value': {'type': 'string', 'description': 'The substring to search for.'}, 'k': {'type': 'integer', 'description': 'The maximum number of values to return. Default is 100.'}}, 'required': ['table', 'column', 'value']}}}\n",
      "sql_db_query:\n",
      "{'type': 'function', 'function': {'name': 'sql_db_query', 'description': 'Execute a SQL query against the database and get back the result. If the query is not correct, an error message will be returned. The maximum number of results to return is 100.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'A valid SQL query to execute.'}, 'k': {'type': 'integer', 'description': 'The maximum number of results to return. Default is 100.'}}, 'required': ['query']}}}\n"
     ]
    }
   ],
   "source": [
    "from src.envs.mimic_iv.tools.sql_db_list_tables import SqlDbListTables\n",
    "from src.envs.mimic_iv.tools.sql_db_schema import SqlDbSchema\n",
    "from src.envs.mimic_iv.tools.value_substring_search import ValueSubstringSearch\n",
    "from src.envs.mimic_iv.tools.sql_db_query import SqlDbQuery\n",
    "\n",
    "print(f\"sql_db_list_tables:\\n{SqlDbListTables.get_info()}\")\n",
    "print(f\"sql_db_schema:\\n{SqlDbSchema.get_info()}\")\n",
    "print(f\"value_substring_search:\\n{ValueSubstringSearch.get_info()}\")\n",
    "print(f\"sql_db_query:\\n{SqlDbQuery.get_info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By feeding this to the `tools_info` in the DB Agent, the agent decides when or when not to use the tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & Evaluation\n",
    "\n",
    "Now, let's see how the User LLM and the DB agent interacts.\n",
    "\n",
    "`run.py` simulates the conversation between the User LLM and the DB Agent. However, you should feed necessary information when running your own DB agent:\n",
    "- model: The backbone model of the DB Agent\n",
    "- agent_strategy: the name of your DB agent. See `src/agent_factory.py` for details. When implemented your own DB agent, you should fill in the TODO: field.\n",
    "- max_concurrency: the number of concurrent samples to run at once. Larger number leads to faster inference.\n",
    "- eval_mode: \"valid\" or \"test\". When running inference on valid_data.json, where you have the gold SQL and the gold answer, it should be \"valid\". On the other hand, when running inference on test_data.json, where you don't have the gold SQL and the gold answer, it should be \"test\". When running on the test set, no evaluation (i.e., outputting final scores) is done. However, you can still see the inference results.\n",
    "\n",
    "\n",
    "Check `run_mimic_iv.sh` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_mimic_iv.sh: line 2: python: command not found\n",
      "run_mimic_iv.sh: line 3: --user_model: command not found\n",
      "run_mimic_iv.sh: line 4: --model: command not found\n",
      "run_mimic_iv.sh: line 5: --agent_strategy: command not found\n",
      "run_mimic_iv.sh: line 6: --temperature: command not found\n",
      "run_mimic_iv.sh: line 7: --seed: command not found\n",
      "run_mimic_iv.sh: line 8: --num_trials: command not found\n",
      "run_mimic_iv.sh: line 9: --max_concurrency: command not found\n",
      "run_mimic_iv.sh: line 10: --eval_mode: command not found\n",
      "run_mimic_iv.sh: line 11: $'\\r': command not found\n",
      "run_mimic_iv.sh: line 14: $'\\r': command not found\n",
      "run_mimic_iv.sh: line 15: $'\\r': command not found\n",
      "run_mimic_iv.sh: line 25: $'\\r': command not found\n",
      "run_mimic_iv.sh: line 26: $'\\r': command not found\n",
      "run_mimic_iv.sh: line 36: $'\\r': command not found\n"
     ]
    }
   ],
   "source": [
    "# running the shell script `run_mimic_iv.sh`. This might take a while.\n",
    "! bash run_mimic_iv.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the inference is done, the results (conversation trajectories between the User LLM and the DB Agent) are saved in the `results/` folder. The name of the result file contains meta information about the inference. You should change the name of the file to `team_{team_number}.json` e.g., `team_1.json` and upload it to KLMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: $0.19\n"
     ]
    }
   ],
   "source": [
    "# checking the total cost of the inference\n",
    "import json\n",
    "import pandas as pd\n",
    "path = 'results/mimic_iv-tool-calling-gpt-4o-mini-0.0_range_0--1_user-gpt-4o-mini-llm_0421105745_valid.json'\n",
    "with open(path, 'r') as f:\n",
    "    results = json.load(f)\n",
    "print(f'Total cost: ${round(sum([l[\"cost\"][\"total_cost\"] for l in results if pd.notna(l[\"cost\"][\"total_cost\"])]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you need to do:\n",
    "1. Implement your own agent in `src/agents/` (`TODO_implement_agent.py`)\n",
    "2. If needed, implement the tools your agent will use in `src/envs/mimic_iv/tools/` (`TODO_implement_tool.py`)\n",
    "3. Change `src/envs/mimic_iv/env.py` to update the tools the DB agent can use in the environment.\n",
    "4. Change `src/agent_factory.py` to make it able to call your implemented agent.\n",
    "5. Change `run_mimic_iv.sh` to do inference & evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8505\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.10:8505\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://59.29.246.30:8505\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# viewing conversation trajectories\n",
    "! streamlit run visualizer.py --server.port 8505"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
